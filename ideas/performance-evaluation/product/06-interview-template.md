# User Interview Template

## Interview Goals

**Validate:**
1. Problem exists and is painful (not just "nice to have")
2. Current solutions are inadequate (willing to switch)
3. Willingness to pay $6-8 PEPM (budget + urgency)
4. Feature priorities (what must exist in MVP vs nice-to-have)

**Duration:** 20-30 minutes

**Format:** Video call (Zoom, Google Meet) - need to see their reactions

---

## Pre-Interview Checklist

- [ ] Send calendar invite with Zoom link 24-48 hours in advance
- [ ] Send confirmation email 2 hours before ("Looking forward to our chat!")
- [ ] Prepare Notion page to take notes (template below)
- [ ] Have business-context.md and wireframes open (don't show unless asked)

---

## Interview Script

### Opening (2 min)

"Hey [Name], thanks for taking the time! I'm building a tool to help managers run better performance reviews, but before I build anything else, I want to make sure I understand the problem deeply.

I've got about 20-25 minutes of questions—mostly about how you currently do reviews and what frustrates you. Sound good?

Quick disclaimer: I might ask some dumb questions, and that's intentional. I'm trying to understand your process without assuming anything."

---

### Part 1: Current State & Pain Points (8-10 min)

#### Q1: Walk me through the last time you ran performance reviews.
*[Let them talk. Don't interrupt. Take notes on tools, time spent, frustrations]*

**Listen for:**
- Tools used (Google Docs, Lattice, nothing)
- Time investment (hours per person)
- Manual vs automated steps
- Emotional language ("nightmare," "chaotic," "embarrassing")

**Follow-up probes:**
- "How long did it take you per person?"
- "What part took the most time?"
- "Did employees see their own reflections before you met with them?"

---

#### Q2: What's the most frustrating part of the current process?
*[Validate the pain is real and specific]*

**Listen for:**
- Copy-pasting documents ("I just copy last quarter's doc")
- Manual peer feedback aggregation ("Took me 3 hours to combine responses")
- No structure ("Every review looks different")
- Legal risk ("I have no documentation if I need to fire someone")

**Follow-up probes:**
- "How often does that happen?"
- "What's the cost if you don't fix this?" (time, turnover, legal risk)

---

#### Q3: How do you collect peer feedback today?
*[Validate peer feedback is painful or non-existent]*

**Listen for:**
- Google Forms + manual aggregation
- Asking in 1:1s (no anonymity, biased)
- Skip it entirely ("Too much work")

**Follow-up probes:**
- "How do you anonymize responses?"
- "How long does it take to aggregate feedback?"
- "Do employees trust the anonymity?"

---

#### Q4: Do employees do self-reviews? If yes, how does that work?
*[Validate self-review + gap analysis value]*

**Listen for:**
- Yes, but manually in Google Docs (no side-by-side comparison)
- No, "I don't have time to set that up"
- Yes, but "I don't know what to do with their self-ratings"

**Follow-up probes:**
- "Do you see their self-ratings before you write yours?" (avoid anchoring bias)
- "Do you ever notice gaps—like they rate themselves lower than you would?"
- "How do you use those gaps in the 1:1 conversation?"

---

### Part 2: Failed Solutions (5-7 min)

#### Q5: Have you looked at tools like Lattice, 15Five, or Small Improvements?
*[Validate competitive positioning]*

**If YES:**
- "Which ones did you evaluate?"
- "Why didn't you choose them?" (price, complexity, features)
- "What would need to change for you to use them?"

**If NO:**
- "Why not?" (don't know they exist, assume too expensive, happy with status quo)

**Listen for:**
- Price objections ("Lattice wanted $2,500/year for 20 people")
- Complexity objections ("Takes 2 weeks to set up")
- Feature mismatch ("We don't need engagement surveys")

---

#### Q6: If money and time weren't an issue, what's your ideal performance review process?
*[Dream state reveals feature priorities]*

**Listen for:**
- "Employees rate themselves first"
- "I want to see gaps before the 1:1"
- "Peer feedback that doesn't take 3 hours to aggregate"
- "Templates so I'm not reinventing the wheel"
- "Historical reviews for promotion decisions"

---

### Part 3: Willingness to Pay (5 min)

#### Q7: How much do you currently spend on performance review tools or related processes?
*[Anchor pricing expectation]*

**Listen for:**
- $0 (Google Docs) but "I waste 10 hours per quarter" = $500-1,000 opportunity cost
- $X/month for Lattice/15Five (validate they have budget)
- "We don't budget for this" (red flag: no buying authority)

---

#### Q8: If I told you there's a tool that does [recap their pain points] for $6-8 per employee per month, what's your gut reaction?
*[Validate pricing]*

**Listen for:**
- "That's reasonable" or "Where do I sign up?" (strong signal)
- "How is that different from [competitor]?" (need to position better)
- "Too expensive, we'll stick with Docs" (fail signal: category doesn't exist)

**Follow-up probes:**
- "What would make that price a no-brainer for you?" (ROI framing)
- "How does that compare to what you pay for other team tools?" (context)

---

#### Q9: When's your next review cycle?
*[Validate urgency]*

**Listen for:**
- "<90 days away" → High urgency (strong buying signal)
- "Next quarter" → Medium urgency (add to nurture list)
- "Not sure, we do them ad hoc" → Low urgency (not ready to buy)

---

### Part 4: Feature Validation (3-5 min)

#### Q10: If this tool existed, which features would you use the most?
*[Prioritize MVP features]*

**Read list:**
1. Employee self-review with side-by-side gap analysis
2. Anonymous peer feedback with auto-aggregation
3. Pre-built templates (Engineer, Manager, Sales Rep)
4. Goal setting and tracking
5. Team analytics dashboard
6. Historical review access

**Listen for:**
- Top 2-3 features they care about (must-haves)
- Features they'd never use (cut from MVP)
- New features they mention (consider for roadmap)

---

### Closing (2 min)

"This was super helpful—thank you! A few last questions:

- **Q11:** If I build this and have a beta ready in [X] months, would you want to try it?"
  - If YES: "Great, I'll add you to the waitlist. Would you be open to paying $1/user for the beta?" (validates real intent)
  - If NO: "No problem—what would need to be true for you to try it?"

- **Q12:** Do you know 2-3 other managers who have this problem? Would you be comfortable introducing me?"
  - [Referrals = strongest validation signal]

- **Q13:** Can I follow up with you as I build this? I'd love to show you early prototypes."
  - [Keeps them warm for beta launch]

"Thanks again—this was really valuable. I'll send you a summary of what I learned and keep you posted on progress!"

---

## Note-Taking Template (Use During Interview)

**Interviewee:** [Name]
**Company:** [Company, size, role]
**Date:** [Date]

---

### Pain Points (What frustrates them)
- [Pain 1]
- [Pain 2]
- [Pain 3]

### Current Process
- Tools used: [Google Docs, Lattice, etc.]
- Time spent: [X hours per person]
- Peer feedback: [How they do it]
- Self-review: [Yes/No, how it works]

### Competitors Evaluated
- [Lattice, 15Five, etc.]
- Why rejected: [Price, complexity, features]

### Willingness to Pay
- Current spend: $[X]/month
- Reaction to $6-8 PEPM: [Strong, neutral, negative]
- Urgency (next review cycle): [Date or "not sure"]

### Feature Priorities (Rank 1-3)
1. [Feature they care about most]
2. [Feature #2]
3. [Feature #3]

### Buying Signals
- [ ] Said "I'd pay for this" or "When can I buy?"
- [ ] Asked about pricing or availability unprompted
- [ ] Gave referrals (2-3 names)
- [ ] Committed to beta (even paid beta at $1/user)
- [ ] Next review cycle <90 days (urgency)

### Red Flags
- [ ] "Interesting, but not a priority" (no urgency)
- [ ] "Too expensive, we'll stick with Docs" (no willingness to pay)
- [ ] "I have to check with my boss" (no budget authority)
- [ ] Can't articulate pain clearly (problem isn't real for them)

### Follow-Up Actions
- [ ] Add to waitlist
- [ ] Send thank-you email with summary
- [ ] Request referrals (if they didn't offer)
- [ ] Schedule follow-up demo (if they're beta-ready)

### Key Quotes (Use in marketing!)
> "[Copy exact quote about pain]"
> "[Copy quote about willingness to pay]"

---

## Post-Interview Checklist

- [ ] Send thank-you email within 24 hours
- [ ] Add to CRM/Notion with qualification status (Hot/Warm/Cold)
- [ ] Update ICP definition if new insights emerge
- [ ] Add quotes to marketing/02-positioning-messaging.md
- [ ] Share insights with team (if applicable)

---

## Interview Analysis (After 10+ Interviews)

### Pattern Recognition
- **What pain points came up >50% of the time?** (Validates product thesis)
- **Which competitors were mentioned most?** (Refine positioning)
- **What objections came up repeatedly?** (Add to sales/04-objection-handling.md)
- **What features did >70% rank as top 3?** (Prioritize in PRD)

### Decision Criteria
- **If 6+ out of 10 said "I'd pay for this"** → GO (build MVP)
- **If 3-5 out of 10 showed interest** → ITERATE (refine ICP or features)
- **If <3 out of 10 showed interest** → PIVOT or KILL (problem isn't painful enough)

---

*Last updated: January 27, 2026*
